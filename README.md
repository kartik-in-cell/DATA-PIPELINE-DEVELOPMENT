# DATA-PIPELINE-DEVELOPMENT

CODTECH INTERNSHIP TASK -1

*COMPANY*: CODTECH IT SOLUTIONS

*NAME*: KARTIK G. SHRIPATRE

*Intern ID*:CT04WT172

*DOMAIN*: DATA SCIENCE

*DURATION*:4 WEEKS

*MENTOR*: NEELA SANTOSH

*Overview*

This project focuses on building a data pipeline for Extract, Transform, Load (ETL) operations using Pandas and Scikit-Learn. The pipeline automates data preprocessing, transformation, and loading into a structured format, making it ready for further analysis or machine learning models.

*Objectives*

Load and preprocess raw dataset.

Handle missing values.

Encode categorical variables and standardize numerical features.

Save the processed data for further analysis.

*Technologies Used*

Python

Pandas

Scikit-Learn

*Implementation Steps*

1.Extract (E): Load the dataset from a CSV file.

2.Transform (T):

Handle missing values (mean imputation for numerical, most frequent for categorical).

One-Hot Encode categorical features.

Standardize numerical features.

3.Load (L): Save the processed dataset as a new CSV file.

*Files Included*

sample_data_100.csv: Raw dataset (100+ rows).

data_pipeline.py: Python script for the ETL process.

processed_data.csv: Preprocessed and transformed dataset.

*How to Run*

Download the sample_data_100.csv file.

Run data_pipeline.py using Python.

The processed data will be saved as processed_data.csv.



